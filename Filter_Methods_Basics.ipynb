{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Filter Methods"
      ],
      "metadata": {
        "id": "pqiJDWeO5-3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important notes**\n",
        "\n",
        "* **In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit.**\n",
        "\n",
        "* **In practice, feature selection should be done after data pre-processing, so ideally, all the categorical variables are encoded into numbers, and then you can asses whether they are correlated with other features.**\n",
        "\n",
        "**Basic methods**\n",
        "\n",
        "* Quasi\n",
        "* constant features\n",
        "* Duplicated features\n",
        "* Duplicated features may arise after one hot encoding of categorical\n",
        "variables"
      ],
      "metadata": {
        "id": "zZj4zXKzLRwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data"
      ],
      "metadata": {
        "id": "d-y2AUEDJ_48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separate dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['target'], axis=1), # drop the target\n",
        "    data['target'], # just the target\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "Uo6wBUx-KCAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constant features\n",
        "\n",
        "Constant features are those that show the same value, just one value, for all the observations of the dataset. In other words, the same value for all the rows of the dataset. These features provide no information that allows a machine learning model to discriminate or predict a target.\n",
        "\n",
        "**Note**\n",
        "\n",
        "* Identifying and removing constant features is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
        "\n",
        "* The DropConstantFeatures class from Feature-engine finds and removes constant and quasi-constant features from a dataset. We can remove constant features by setting the parameter tol to 1, or quasi-constant with smaller values for tol."
      ],
      "metadata": {
        "id": "pcJSi8rk6B4t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKxzuDJTigeW"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import the DropConstantFeatures class from feature_engine\n",
        "# Import the class that helps remove features with constant values\n",
        "from feature_engine.selection import DropConstantFeatures\n",
        "\n",
        "# Step 2: Initialize the DropConstantFeatures selector with specified parameters\n",
        "# Set up the selector to detect constant features with no tolerance for variability\n",
        "sel = DropConstantFeatures(tol=1, variables=None, missing_values='raise')\n",
        "\n",
        "# Step 3: Fit the selector to the training data to identify constant features\n",
        "# Fit the model to find features with constant values in the training data\n",
        "sel.fit(X_train)\n",
        "\n",
        "# Step 4: Access the list of constant features identified during fitting\n",
        "# Retrieve the list of features that were found to be constant\n",
        "sel.features_to_drop_\n",
        "\n",
        "# Step 5: Count the number of constant features in the dataset\n",
        "# Find out how many features are constant\n",
        "len(sel.features_to_drop_)\n",
        "\n",
        "# Step 6: Examine the unique values of the first constant feature\n",
        "# Display the unique value(s) of the first constant feature\n",
        "X_train[sel.features_to_drop_[0]].unique()\n",
        "\n",
        "# Step 7: Remove constant features from the training data\n",
        "# Drop the constant features from the training data\n",
        "X_train = sel.transform(X_train)\n",
        "# Step 8: Remove constant features from the test data using the same transformation\n",
        "# Apply the same transformation to the test data\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "# Step 9: Display the shape of the training and test datasets after removing constant features\n",
        "# Show the new dimensions of both training and test sets\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quasi-constant features\n",
        "\n",
        "Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little, if any, information that allows a machine learning model to discriminate or predict a target. But there can be exceptions. So you should be careful when removing these type of features.\n",
        "\n",
        "**Note**\n",
        "\n",
        "* Identifying and removing quasi-constant features, is an easy first step towards feature selection and more interpretable machine learning models."
      ],
      "metadata": {
        "id": "pl_5WnnZ6tN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Initialize the DropConstantFeatures selector with a tolerance for quasi-constant features\n",
        "# Set up the selector to identify quasi-constant features, keeping variables with less than 0.2% variance\n",
        "sel = DropConstantFeatures(tol=0.998, variables=None, missing_values='raise')\n",
        "\n",
        "# Step 2: Fit the selector to the training data to identify quasi-constant features\n",
        "# Fit the model to find quasi-constant features in the training data\n",
        "sel.fit(X_train)\n",
        "\n",
        "# Step 3: Count the number of quasi-constant features in the dataset\n",
        "# Determine how many features have very low variability\n",
        "len(sel.features_to_drop_)\n",
        "\n",
        "# Step 4: Retrieve the list of quasi-constant features identified\n",
        "# Get the list of features that were found to be quasi-constant\n",
        "sel.features_to_drop_\n",
        "\n",
        "# Step 5: Calculate the percentage of observations for each unique value in the first quasi-constant feature\n",
        "# Show the distribution of values for the first quasi-constant feature\n",
        "var = sel.features_to_drop_[0]\n",
        "X_train[var].value_counts(normalize=True)\n",
        "\n",
        "# Step 6: Explore the distribution of another quasi-constant feature\n",
        "# Show the distribution of values for the third quasi-constant feature\n",
        "var = sel.features_to_drop_[2]\n",
        "X_train[var].value_counts(normalize=True)\n",
        "\n",
        "# Step 7: Remove quasi-constant features from the training data\n",
        "# Drop the quasi-constant features from the training data\n",
        "X_train = sel.transform(X_train)\n",
        "# Step 8: Remove quasi-constant features from the test data using the same transformation\n",
        "# Apply the same transformation to the test data\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "# Step 9: Display the shape of the training and test datasets after removing quasi-constant features\n",
        "# Show the new dimensions of both training and test sets\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "m7_5petl03Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Duplicated features\n",
        "\n",
        "Often datasets contain duplicated features, that is, features that despite having different names, are identical.\n",
        "\n",
        "In addition, we may often introduce duplicated features when performing one hot encoding of categorical variables, particularly if our datasets have many and /or highly cardinal categorical variables.\n",
        "\n",
        "Identifying and removing duplicated, and therefore redundant features, is an easy first step towards feature selection and more interpretable machine learning models.\n",
        "\n",
        "**Note**\n",
        "* Finding duplicated features can be a computationally costly operation in Python, therefore depending on the size of your dataset, you might not always be able to do it.\n",
        "* This method that I describe here to find duplicated features works for both numerical and categorical variables."
      ],
      "metadata": {
        "id": "YYdBLXA17BF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import DropDuplicateFeatures and DropConstantFeatures from feature_engine\n",
        "# Import the classes to remove duplicate and constant features\n",
        "from feature_engine.selection import DropDuplicateFeatures, DropConstantFeatures\n",
        "\n",
        "# Step 2: Set up the DropDuplicateFeatures selector with the specified parameters\n",
        "# Initialize the selector to identify duplicate features\n",
        "sel = DropDuplicateFeatures(variables=None, missing_values='raise')\n",
        "\n",
        "# Step 3: Fit the selector to the training data to find duplicate features\n",
        "# Identify duplicate features in the training data (this might take some time)\n",
        "sel.fit(X_train)\n",
        "\n",
        "# Step 4: Retrieve the sets of duplicated features\n",
        "# Access the list of feature sets that are duplicates of each other\n",
        "sel.duplicated_feature_sets_\n",
        "\n",
        "# Step 5: Retrieve the features that will be dropped (one from each duplicate set)\n",
        "# Get the list of features that are marked to be removed\n",
        "sel.features_to_drop_\n",
        "\n",
        "# Step 6: Check how many duplicated features will be removed\n",
        "# Count the number of features that will be dropped\n",
        "len(sel.features_to_drop_)\n",
        "\n",
        "# Step 7: Remove the duplicated features from the training data\n",
        "# Drop the duplicated features from the training dataset\n",
        "X_train = sel.transform(X_train)\n",
        "# Step 8: Remove the duplicated features from the test data using the same transformation\n",
        "# Apply the same transformation to the test data\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "# Step 9: Display the shape of the training and test datasets after removing duplicate features\n",
        "# Show the new dimensions of both training and test sets\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "87VN6ltY7BLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stack Feature selection in a Pipeline\n",
        "\n",
        "We can perform both steps together by setting up the transformers within a pipeline.\n"
      ],
      "metadata": {
        "id": "-1DZlP5AKMy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a pipeline with DropConstantFeatures and DropDuplicateFeatures\n",
        "# Set up a pipeline that removes quasi-constant and duplicated features\n",
        "pipe = Pipeline([\n",
        "    ('constant', DropConstantFeatures(tol=0.998)),\n",
        "    ('duplicated', DropDuplicateFeatures()),\n",
        "])\n",
        "\n",
        "# Step 2: Fit the pipeline to the training data to identify features to remove\n",
        "# Fit the pipeline to detect quasi-constant and duplicate features in the training data\n",
        "pipe.fit(X_train)\n",
        "\n",
        "# Step 3: Transform the training data by removing identified features\n",
        "# Remove the quasi-constant and duplicated features from the training data\n",
        "X_train = pipe.transform(X_train)\n",
        "# Step 4: Transform the test data by applying the same removal process\n",
        "# Remove the quasi-constant and duplicated features from the test data\n",
        "X_test = pipe.transform(X_test)\n",
        "\n",
        "# Step 5: Display the shape of the training and test datasets after feature removal\n",
        "# Show the new dimensions of both training and test sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Step 6: Get the number of quasi-constant features that were removed\n",
        "# Check how many quasi-constant features were dropped\n",
        "len(pipe.named_steps['constant'].features_to_drop_)\n",
        "\n",
        "# Step 7: Access the list of duplicated features that were removed\n",
        "# Retrieve the list of features that were dropped due to duplication\n",
        "pipe.named_steps['duplicated'].features_to_drop_"
      ],
      "metadata": {
        "id": "YkGIzjq5KNdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}